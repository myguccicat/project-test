# app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from dotenv import load_dotenv
from collections import Counter
import itertools
import io
from sklearn.decomposition import PCA
import plotly.express as px
import plotly.io as pio
import xlsxwriter
import jieba
from sklearn.feature_extraction.text import CountVectorizer
# --- Other imports ---
from modules.crawler import fetch_articles
from modules.nlp import clean_text
from modules.topic_model import extract_topics
from modules.sentiment import analyze_sentiments, summarize_text
from modules.suggestion import generate_business_suggestions
from modules.utils import log_app_usage  # <--- æ–°å¢ž
from cache.cache_utils import load_cache, save_cache

# --- Global Settings ---
pio.templates.default = "plotly_white"
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']  # å¾®è»Ÿæ­£é»‘é«”
plt.rcParams['axes.unicode_minus'] = False  # è§£æ±ºè² è™Ÿ "-" é¡¯ç¤ºå•é¡Œ

# --- Load API Key from .env ---
load_dotenv()

# --- Streamlit App Config ---
st.set_page_config(page_title="è¶¨å‹¢åˆ†æžèˆ‡å•†æ¥­å»ºè­°", layout="wide")
st.title("ðŸ” AIè¶¨å‹¢é¡§å•")

# --- User Input ---
keyword = st.text_input("è«‹è¼¸å…¥é—œéµå­—:")
mode = st.selectbox("é¸æ“‡è³‡æ–™ä¾†æº:", ["ptt", "news"])
vectorizer = CountVectorizer()

if st.button("åŸ·è¡Œåˆ†æž") and keyword:
    log_app_usage(f"[App] User Input Keyword: {keyword} ({mode})")  # <--- è¨˜éŒ„è¼¸å…¥

    cache_data = load_cache(keyword, mode)

    if cache_data:
        st.info("ä½¿ç”¨å¿«å–è³‡æ–™ (1 å°æ™‚å…§æœ€æ–°)")
        articles = cache_data
        log_app_usage(f"[App] Cache Hit: {keyword} ({mode})")  # <--- è¨˜éŒ„å¿«å–å‘½ä¸­
    else:
        api_key = os.getenv("NEWS_API_KEY")
        articles = fetch_articles(keyword, mode=mode, limit=10, api_key=api_key)
        if articles:
            save_cache(keyword, mode, articles)
            log_app_usage(f"[App] Cache Miss & Fetched: {keyword} ({mode})")  # <--- è¨˜éŒ„å¿«å– miss
        else:
            st.warning("æ‰¾ä¸åˆ°ç›¸é—œæ–‡ç« ")
            log_app_usage(f"[App] Fetch Failed: {keyword} ({mode})")
            articles = []

    if articles:
        # --- NLP Processing ---
        texts = [clean_text(a["title"]) for a in articles]
        topics = extract_topics(texts, n_clusters=3)
        sentiment_result = analyze_sentiments(texts)
        sentiment_avg = sentiment_result["average"]
        suggestions = generate_business_suggestions(topics, sentiment_result["counts"], sentiment_avg)
        log_app_usage(f"[App] Analysis Completed: {keyword} ({mode})")  # <--- è¨˜éŒ„åˆ†æžå®Œæˆ

        # --- Display Articles DataFrame ---
        st.subheader("ðŸ“„ æ–‡ç« åˆ—è¡¨")
        articles_df = pd.DataFrame(articles)
        st.dataframe(articles_df, use_container_width=True)

        # --- Display Topics ---
        st.subheader("ðŸ“ ä¸»é¡Œå»ºæ¨¡çµæžœ")
        st.write(topics)

        # --- Sentiment Analysis è¡¨æ ¼ ---
        st.subheader("ðŸ“Š æƒ…ç·’åˆ†æžçµæžœ")
        sentiment_df = pd.DataFrame([{
            "æ¨™é¡Œ": d["title"],
            "æƒ…ç·’æ¨™ç±¤": d["label"],
            "æƒ…ç·’åˆ†æ•¸": d["score"]
        } for d in sentiment_result["details"]])
        st.dataframe(sentiment_df, use_container_width=True)

        # --- Sentiment Distribution Chart ---
        st.subheader("ðŸ“ˆ æƒ…ç·’åˆ†ä½ˆé•·æ¢åœ–")
        fig, ax = plt.subplots()
        sns.histplot(sentiment_result["scores"], bins=10, kde=True, ax=ax)
        ax.set_xlabel("æƒ…ç·’åˆ†æ•¸")
        ax.set_ylabel("æ–‡ç« æ•¸é‡")
        st.pyplot(fig)

        # --- Drill-Down äº’å‹•å±•é–‹ ---
        st.subheader("ðŸ”Ž ä¸»é¡Œæ–‡ç« ç´°ç¯€ Drill-down")
        st.info("è«‹é»žæ“Šä¸‹æ–¹ Scatter Plot çš„é»žï¼Œå°‡è‡ªå‹•å±•é–‹è©² Cluster ç´°ç¯€")
        selected_cluster = st.selectbox("é¸æ“‡è¦æª¢è¦–çš„ Cluster ID", [topic["cluster"] for topic in topics])

        for topic in topics:
            if topic["cluster"] == selected_cluster:
                st.markdown(f"### Cluster {topic['cluster']} â€” é—œéµå­—: {', '.join(topic['keywords'])}")
                for idx in topic["article_idxs"]:
                    detail = sentiment_result["details"][idx]
                    summary = summarize_text(detail["title"])
                    with st.expander(f"ã€{detail['label']}ã€‘{detail['title']} (åˆ†æ•¸: {detail['score']:.2f})"):
                        st.write(f"æ‘˜è¦ï¼š{summary}")

    # --- Drill-down åŒ¯å‡ºæŒ‰éˆ• - Export Cluster Report ---
    if st.button("ðŸ“¥ åŒ¯å‡ºè©² Cluster æ–‡ç« æƒ…ç·’å ±å‘Š"):
        export_data = []
        for topic in topics:
            if topic["cluster"] == selected_cluster:
                for idx in topic["article_idxs"]:
                    detail = sentiment_result["details"][idx]
                    summary = summarize_text(detail["tiltle"])
                    export_data.append({"æ¨™é¡Œ": detail["title"],
                        "æƒ…ç·’æ¨™ç±¤": detail["label"],
                        "æƒ…ç·’åˆ†æ•¸": detail["score"],
                        "æ‘˜è¦": summary
                        })
                    
        # åŒ¯å‡ºè³‡æ–™æœ‰æ±è¥¿æ‰åŸ·è¡ŒåŒ¯å‡º
        if export_data:
            export_df = pd.DataFrame(export_data)
            # è½‰æˆ Excel bytes
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                export_df.to_excel(writer, index=False, sheet_name='Cluster_Report')
            output.seek(0)
            # ä¸‹è¼‰æŒ‰éˆ•
            st.download_button(
                label="ðŸ“„ ä¸‹è¼‰ Excel å ±å‘Š",
                data=output,
                file_name=f"Cluster_{selected_cluster}_Report.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("è©² Cluster å…§æ²’æœ‰æ–‡ç« å¯ä»¥åŒ¯å‡ºã€‚")

        # --- Topic Co-occurrence Heatmap (Real Data) ---
        st.subheader("ðŸ—ºï¸ ä¸»é¡Œé—œè¯ç†±åŠ›åœ–")
        word_pairs = list(itertools.chain.from_iterable(
            itertools.combinations(topic["keywords"], 2) for topic in topics
        ))
        pair_counts = Counter(word_pairs)
        unique_words = sorted(set(itertools.chain.from_iterable(word_pairs)))
        matrix = pd.DataFrame(0, index=unique_words, columns=unique_words)
        for (w1, w2), count in pair_counts.items():
            matrix.at[w1, w2] = count
            matrix.at[w2, w1] = count

        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.heatmap(matrix, annot=True, cmap="YlGnBu", ax=ax2)
        st.pyplot(fig2)

        # --- Topic Sentiment Distribution Dashboard ---
        st.subheader("ðŸ“Š ä¸»é¡Œæƒ…ç·’åˆ†ä½ˆ Dashboard ç¸½çµ")
        summary_data = []
        for topic in topics:
            sentiments = [sentiment_result["details"][i]["label"] for i in topic["article_idxs"]]
            counts = Counter(sentiments)
            summary_data.append({
                "Cluster": topic["cluster"],
                "Keywords": ", ".join(topic["keywords"]),
                "æ­£å‘": counts.get("æ­£å‘", 0),
                "ä¸­ç«‹": counts.get("ä¸­ç«‹", 0),
                "è² å‘": counts.get("è² å‘", 0),
                "ç¸½æ•¸": len(topic["article_idxs"])
            })
        summary_df = pd.DataFrame(summary_data)
        st.dataframe(summary_df)
        
        # æ‰¾å‡ºæ­£å‘æœ€å¤š & è² å‘æœ€å¤šçš„ä¸»é¡Œ
        most_positive = summary_df.sort_values(by="æ­£å‘", ascending=False).iloc[0]
        most_negative = summary_df.sort_values(by="è² å‘", ascending=False).iloc[0]

        st.markdown(f"âœ… **æ­£å‘è²é‡æœ€é«˜ä¸»é¡Œï¼š** Cluster {most_positive['Cluster']} ({most_positive['Keywords']}) â€” {most_positive['æ­£å‘']} ç¯‡")
        st.markdown(f"âš ï¸ **è² å‘è²é‡æœ€é«˜ä¸»é¡Œï¼š** Cluster {most_negative['Cluster']} ({most_negative['Keywords']}) â€” {most_negative['è² å‘']} ç¯‡")

        # --- Business Suggestions ---
        st.subheader("ðŸ’¡ å•†æ¥­å»ºè­°")
        for i, suggestion in enumerate(suggestions, 1):
            st.markdown(f"**{i}. {suggestion}**")
        log_app_usage(f"[App] Suggestion Ready for: {keyword}")  # <--- è¨˜éŒ„å»ºè­°å®Œæˆ
        
        # --- 2D Cluster Scatter Plot ---
        st.subheader("ðŸ–¼ï¸ Cluster 2D Scatter Plot (è¦–è¦ºåŒ–)")
        # 1. æ–‡ç« å‘é‡åŒ– (TF-IDF)
        tokenized_texts = [' '.join(jieba.lcut(t)) for t in texts]
        X = CountVectorizer().fit_transform(tokenized_texts)
        # 2. PCA é™åˆ° 2 ç¶­
        X_pca = PCA(n_components=2).fit_transform(X.toarray())
        # 3. æº–å‚™ DataFrame
        scatter_data = []
        for i, (x, y) in enumerate(X_pca):
            cluster_id = next((topic["cluster"] for topic in topics if i in topic["article_idxs"]), None)
            scatter_data.append({
                "æ¨™é¡Œ": articles[i]["title"],
                "æƒ…ç·’æ¨™ç±¤": sentiment_result["details"][i]["label"],
                "Cluster": cluster_id,
                "X": x,
                "Y": y
            })
        scatter_df = pd.DataFrame(scatter_data)
        # 4. ç•«æ•£é»žåœ–
        fig3 = px.scatter(
            scatter_df, x="X", y="Y", color="Cluster",
            hover_data=["æ¨™é¡Œ", "æƒ…ç·’æ¨™ç±¤"],
            title="æ–‡ç« èšé¡žåˆ†ä½ˆ"
        )
        selected_point = st.plotly_chart(fig3, use_container_width=True).selected_points

        if selected_point:
            selected_idx = selected_point[0]["pointIndex"]
            clicked_cluster = scatter_df.iloc[selected_idx]["Cluster"]
            st.session_state.clicked_cluster = clicked_cluster
        else:
            st.session_state.clicked_cluster = None
    # --- Dashboard ç¸½è¦½åŒ¯å‡º ---Export Dashboard Summary
    if st.button("ðŸ“¥ åŒ¯å‡º Dashboard ç¸½è¦½å ±å‘Š"):
        output_summary = io.BytesIO()
        with pd.ExcelWriter(output_summary, engine='xlsxwriter') as writer:
            summary_df.to_excel(writer, index=False, sheet_name='Dashboard_Summary')
        output_summary.seek(0)

        st.download_button(
            label="ðŸ“Š ä¸‹è¼‰ Dashboard ç¸½è¦½å ±å‘Š",
            data=output_summary,
            file_name=f"Dashboard_Summary_{keyword}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
# --- End of App ---
# --- Run the Streamlit app ---