# app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from dotenv import load_dotenv
from collections import Counter
import itertools

# --- Load API Key from .env ---
load_dotenv()

# --- Other imports ---
from modules.crawler import fetch_articles
from modules.nlp import clean_text
from modules.topic_model import extract_topics
from sklearn.feature_extraction.text import CountVectorizer
from modules.sentiment import analyze_sentiments
from modules.suggestion import generate_business_suggestions
from modules.utils import log_app_usage  # <--- æ–°å¢ž
from cache.cache_utils import load_cache, save_cache

# --- Streamlit App Logic ---
st.set_page_config(page_title="è¶¨å‹¢åˆ†æžèˆ‡å•†æ¥­å»ºè­°", layout="wide")
st.title("ðŸ” é—œéµå­—è¶¨å‹¢åˆ†æžèˆ‡å•†æ¥­å»ºè­°å·¥å…·")

keyword = st.text_input("è«‹è¼¸å…¥é—œéµå­—:")
mode = st.selectbox("é¸æ“‡è³‡æ–™ä¾†æº:", ["ptt", "news"])
vectorizer = CountVectorizer()

if st.button("åŸ·è¡Œåˆ†æž") and keyword:
    log_app_usage(f"[App] User Input Keyword: {keyword} ({mode})")  # <--- è¨˜éŒ„è¼¸å…¥

    cache_data = load_cache(keyword, mode)

    if cache_data:
        st.info("ä½¿ç”¨å¿«å–è³‡æ–™ (1 å°æ™‚å…§æœ€æ–°)")
        articles = cache_data
        log_app_usage(f"[App] Cache Hit: {keyword} ({mode})")  # <--- è¨˜éŒ„å¿«å–å‘½ä¸­
    else:
        api_key = os.getenv("NEWS_API_KEY")
        articles = fetch_articles(keyword, mode=mode, limit=10, api_key=api_key)
        if articles:
            save_cache(keyword, mode, articles)
            log_app_usage(f"[App] Cache Miss & Fetched: {keyword} ({mode})")  # <--- è¨˜éŒ„å¿«å– miss
        else:
            st.warning("æ‰¾ä¸åˆ°ç›¸é—œæ–‡ç« ")
            log_app_usage(f"[App] Fetch Failed: {keyword} ({mode})")
            articles = []

    if articles:
        texts = [clean_text(a["title"]) for a in articles]
        topics = extract_topics(texts, vectorizer)
        sentiments = [analyze_sentiments(t) for t in texts]
        suggestions = generate_business_suggestions(topics, sentiments)

        log_app_usage(f"[App] Analysis Completed: {keyword} ({mode})")  # <--- è¨˜éŒ„åˆ†æžå®Œæˆ

        # --- Display Articles DataFrame ---
        st.subheader("ðŸ“„ æ–‡ç« åˆ—è¡¨")
        articles_df = pd.DataFrame(articles)
        st.dataframe(articles_df, use_container_width=True)

        # --- Display Topics ---
        st.subheader("ðŸ“ ä¸»é¡Œå»ºæ¨¡çµæžœ")
        st.write(topics)

        # --- Sentiment Analysis ---
        st.subheader("ðŸ“Š æƒ…ç·’åˆ†æžçµæžœ")
        sentiment_df = pd.DataFrame({"æ¨™é¡Œ": texts, "æƒ…ç·’åˆ†æ•¸": sentiments})
        st.dataframe(sentiment_df, use_container_width=True)

        # --- Sentiment Distribution Chart ---
        st.subheader("ðŸ“ˆ æƒ…ç·’åˆ†ä½ˆé•·æ¢åœ–")
        fig, ax = plt.subplots()
        sns.histplot(sentiments, bins=10, kde=True, ax=ax)
        ax.set_xlabel("æƒ…ç·’åˆ†æ•¸")
        ax.set_ylabel("æ–‡ç« æ•¸é‡")
        st.pyplot(fig)

        # --- Topic Co-occurrence Heatmap (Real Data) ---
        st.subheader("ðŸ—ºï¸ ä¸»é¡Œé—œè¯ç†±åŠ›åœ–")
        word_pairs = []
        for topic in topics:
            words = topic.split()
            word_pairs.extend(itertools.combinations(words, 2))

        pair_counts = Counter(word_pairs)
        unique_words = sorted(set(itertools.chain.from_iterable(word_pairs)))

        co_occurrence_matrix = pd.DataFrame(0, index=unique_words, columns=unique_words)
        for (w1, w2), count in pair_counts.items():
            co_occurrence_matrix.at[w1, w2] = count
            co_occurrence_matrix.at[w2, w1] = count

        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.heatmap(co_occurrence_matrix, annot=True, cmap="YlGnBu", ax=ax2)
        st.pyplot(fig2)

        # --- Business Suggestions ---
        st.subheader("ðŸ’¡ å•†æ¥­å»ºè­°")
        for i, suggestion in enumerate(suggestions, 1):
            st.markdown(f"**{i}. {suggestion}**")

        log_app_usage(f"[App] Suggestion Ready for: {keyword}")  # <--- è¨˜éŒ„å»ºè­°å®Œæˆ

from modules.crawler import fetch_articles

result = fetch_articles("ç”Ÿæˆå¼AI", mode="ptt", limit=5)
print(result)
# --- Run the Streamlit app ---